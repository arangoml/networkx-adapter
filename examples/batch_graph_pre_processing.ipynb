{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teHHQQILe_dS"
   },
   "source": [
    "## Get Raw Data for Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangoml/networkx-adapter/blob/master/examples/batch_graph_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G-oxhBfae8Ae"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!git clone -b 0.0.0.2.5.3 https://github.com/arangoml/networkx-adapter.git\n",
    "!rsync -av networkx-adapter/examples/ ./ --exclude=.git\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzKGdXzUenuM"
   },
   "source": [
    "## Preprocessing ITSM Data\n",
    "The purpose of this notebook is to prepare the data in a format suitable for machine learning. The dataset consists of a few numerical and many categorical attributes. The numerical attributes are discretized. The embedding for the categorical values is developed similar to developing embeddings for words in NLP (see https://pytorch.org/tutorials/beginner/nlp/word_embeddings_tutorial.html). Each categorical value is mapped to a unique integer. The encoded data that is presented to the embedding layer is a sequence of integers, with each integer corresponding to a word, This notebook performs this mapping. It also encodes unknown values to a 'UNKNOWN' category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bkRP-4eBenuN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fp = \"data/incident_event_log.csv\"\n",
    "df = pd.read_csv(fp)\n",
    "df['reassigned'] = df['reassigned'] = df['reassignment_count'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGEszr3GenuT"
   },
   "source": [
    "## Discretize the numerical attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6mTJ90venuU"
   },
   "outputs": [],
   "source": [
    "numeric = ['sys_mod_count', 'reopen_count']\n",
    "dfn = df[numeric]\n",
    "dcols = []\n",
    "for col in numeric:\n",
    "    dlabel = 'D_' + col\n",
    "    labels = [dlabel +'_' + str(c) for c in range(5)]\n",
    "    dcols.append(dlabel)\n",
    "    dfn[dlabel] = pd.qcut(dfn[col].rank(method='first'),5, labels = labels, duplicates = 'drop')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_EF79pOenuZ"
   },
   "outputs": [],
   "source": [
    "dfn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lE815N7venud"
   },
   "source": [
    "## Isolate the attributes used for the analysis \n",
    "1. Remove the timestamp attributes\n",
    "2. Remove the numeric attributes. The discretized version of these attributes is added subsequently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxUt-5Enenue"
   },
   "outputs": [],
   "source": [
    "attributes = df.columns.tolist()\n",
    "remove = [ 'made_sla', 'opened_at', 'resolved_at','sys_created_at', 'caller_id', 'closed_at',\\\n",
    "          'notify', 'sys_updated_by','sys_created_by', 'number', 'sys_updated_at', 'reassigned' ]\n",
    "exclude = remove + numeric\n",
    "keep = list(set(attributes) - set(exclude)) \n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DbVuZhgsenuk"
   },
   "outputs": [],
   "source": [
    "df_cat_vars = df[keep]\n",
    "df_cat_vars = df_cat_vars.replace(to_replace = '?', value = 'UNKNOWN')\n",
    "df_cat_vars =  pd.concat([df_cat_vars, dfn[dcols]], axis = 1)\n",
    "df['made_sla'] = df['made_sla'].map({True: 1, False: 0})\n",
    "\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vto4QKbxenuo"
   },
   "outputs": [],
   "source": [
    "df['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ogJ0oAlSenus"
   },
   "outputs": [],
   "source": [
    "cols = df_cat_vars.columns.tolist()\n",
    "vocab_size = 0\n",
    "for c in cols:\n",
    "    print(\"Num unique vals for category \" + str(c) + \" = \" + str(df_cat_vars[c].nunique()))\n",
    "    vocab_size += df_cat_vars[c].nunique()\n",
    "print(\"Vocab size: %s\" % vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juRDL5_lenuw"
   },
   "source": [
    "## Recode the categorical values to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oVM1rplIenux"
   },
   "outputs": [],
   "source": [
    "UNKNOWN_VAL = 1\n",
    "cat_cols = df_cat_vars.columns.tolist()\n",
    "cat_int_map = {col: dict() for col in cat_cols}\n",
    "int_index = 2\n",
    "for c in cat_cols:\n",
    "    unique_col_values = df_cat_vars[c].unique().tolist()\n",
    "    col_int_map = cat_int_map[c]\n",
    "    for uv in unique_col_values:\n",
    "        if uv == 'UNKNOWN':\n",
    "            col_int_map[uv] = UNKNOWN_VAL\n",
    "        else:\n",
    "            col_int_map[uv] = int_index\n",
    "            int_index +=1\n",
    "    df_cat_vars[c] = df_cat_vars[c].map(cat_int_map[c])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lH6qzefOenu0"
   },
   "outputs": [],
   "source": [
    "combined_cat_int_map = dict()\n",
    "for col in cat_int_map.keys():\n",
    "    for cat_val, int_map in cat_int_map[col].items():\n",
    "        combined_cat_int_map[cat_val] = int_map\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jH9uA2IVenu3"
   },
   "source": [
    "## Write preprocessed raw data to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWMHA7eSenu4"
   },
   "outputs": [],
   "source": [
    "fp_cat_int_map = \"data/category_to_integer_map.csv\"\n",
    "df_map = pd.DataFrame(combined_cat_int_map, index = [0])\n",
    "df_map = df_map.T\n",
    "df_map = df_map.reset_index()\n",
    "df_map.columns = [\"cat_value\", \"assigned_integer\"]\n",
    "df_map.to_csv(fp_cat_int_map, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzbT2d08enu7"
   },
   "outputs": [],
   "source": [
    "add_to_cat_vars = ['number','sys_updated_at', 'reassigned'] \n",
    "df = pd.concat([df[add_to_cat_vars], df_cat_vars], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDA8_L5-enu-"
   },
   "outputs": [],
   "source": [
    "df['sys_updated_at'] = pd.to_datetime(df['sys_updated_at']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qN8WD2teenvB"
   },
   "outputs": [],
   "source": [
    "df['sys_updated_at'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93OcLjSVenvE"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by = ['number', 'sys_updated_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WK00OhfzenvH"
   },
   "outputs": [],
   "source": [
    "fp = 'data/pp_batch_incident_event_log.csv'\n",
    "df.to_csv(fp, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0DcHNc36envK"
   },
   "outputs": [],
   "source": [
    "df['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0GqTrpLVenvM"
   },
   "outputs": [],
   "source": [
    "int_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n0Jwy-OenvP"
   },
   "source": [
    "## Generate data for learning\n",
    "The data used for learning has the raw data summarized by incident, i.e. , the raw data for each incident is grouped and summarized. A sample of the data used for learning can be viewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odZ5S1XienvQ"
   },
   "outputs": [],
   "source": [
    "dfgb = df.groupby(by = ['number'])\n",
    "df_pp = df.loc[dfgb.sys_updated_at.idxmax()]\n",
    "df_pp = df_pp.reset_index()\n",
    "cols = df_pp.columns.tolist()\n",
    "cols.remove('index')\n",
    "df_pp = df_pp[cols]\n",
    "fprp = \"data/pp_recoded_incident_event_log.csv\"\n",
    "df_pp.to_csv(fprp, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ_27dx5envT"
   },
   "outputs": [],
   "source": [
    "df_pp['reassigned'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnNYbdqzenvX"
   },
   "outputs": [],
   "source": [
    "df_pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Bi1Wyaienvb"
   },
   "outputs": [],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p77zo3FUenve"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "batch_graph_pre_processing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangoml/networkx-adapter/blob/master/examples/ITSM_ArangoDB_Adapter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjUp8oZA_0EL"
   },
   "source": [
    "# Predicting IT Service Ticket Reassingnment Using RGCN (DGL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6qWopH1_0EN"
   },
   "source": [
    "This notebook provides the details of applying a __Graph Convolutional Network(GCN)__ to predict if an IT service ticket will be reassigned. The workflow associated with ticket resolution has a convinient graph representation. The raw data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Incident+management+process+enriched+event+log) is loaded into ArangoDB using the [ITSM_data_loader python file](files/ITSM_data_loader.py). The [DGL](https://github.com/dmlc/dgl) library is used to create the __GCN__ model that is used to predict ticket reassignment. The graph associated with this prediction task is _heterogeneous_. This means that the graph has multiple types of vertices. In this example, the _incident_ (for which the ticket is created), the _support_org_ (the organization resolving the ticket), the _customer_ (who opened the ticket) and the _vendor_ (if the ticket is associated with an external product) are the different vertices in the graph (see [working with heterographs in DGL](https://docs.dgl.ai/en/0.4.x/tutorials/hetero/1_basics.html) for more details). Each of these vertices has attributes that are utilized in predicting the _reassignment_ status of a ticket. In this work, both the graph structure associated with a particular _incident_ and the properties associated with the vertices of the graph are used in the __GCN__. In particular, the semi-supervised model described in [\"working with heterographs in DGL\"](https://docs.dgl.ai/en/0.4.x/tutorials/hetero/1_basics.html), based on work by [Kipf et al.,](https://arxiv.org/abs/1703.06103) will be used here. The details of the implementaion are as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K6LQVNyO_0EQ"
   },
   "source": [
    "## Install Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FF_RsnbzZsAM"
   },
   "outputs": [],
   "source": [
    "%%capture cap_out --no-stderr\n",
    "!git clone -b master https://github.com/arangoml/networkx-adapter.git\n",
    "!rsync - av networkx-adapter/examples / . / --exclude = .git\n",
    "!pip3 install networkx\n",
    "!pip3 install matplotlib\n",
    "!pip install --index-url https://test.pypi.org/simple/ adbnx-adapter==0.0.0.2.5.3\n",
    "!pip3 install pyarango\n",
    "!pip3 install python-arango\n",
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ly7pC2qEAjdL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('./networkx-adapter/examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50Xg1Wz1_0Eb"
   },
   "source": [
    "## Obtain an Oasis Connection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "punGc278_0Ec"
   },
   "source": [
    "Oasis is the __ArangoDB__ managed service database offering. We will use __Oasis__ for this work. This permits us to use __ArangoDB__ without worrying about the details of installation and set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NhIdp2rNaos7"
   },
   "outputs": [],
   "source": [
    "import oasis\n",
    "con = oasis.getTempCredentials()\n",
    "\n",
    "print()\n",
    "print(\"https://{}:{}\".format(con[\"hostname\"], con[\"port\"]))\n",
    "print(\"Username: \" + con[\"username\"])\n",
    "print(\"Password: \" + con[\"password\"])\n",
    "print(\"Database: \" + con[\"dbName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JWWsUIV0_0Ei"
   },
   "source": [
    "## Load the Data into Oasis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_HoUDu8R_0Ej"
   },
   "source": [
    "The _arangorestore_ utility is used to load the database into the __Oasis__ instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o5Q1aESiatNB"
   },
   "outputs": [],
   "source": [
    "\n",
    "!./tools/arangorestore -c none --server.endpoint http+ssl://{con[\"hostname\"]}:{con[\"port\"]} --server.username {con[\"username\"]} --server.database {con[\"dbName\"]} --server.password {con[\"password\"]} --default-replication-factor 3  --input-directory \"data/dgl_data_dump\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZqwkRxVx_0Eo"
   },
   "source": [
    "## Create the ArangoDB DGL Adapter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b4c-5Cpl_0Ep"
   },
   "source": [
    "The __ArangoDB DGL Adapter__ will create a __dgl heterograph__ from __ArangoDB__. To create the __dgl heterograph__ we will need to provide a description of the graph that we would like to create. This is done by describing the vertices and edges of the graph using a _dictionary_ data structure. The details of the vertices and edges for this example are shown below. The __ArangoDB DGL Adapter__ specifies the details of the heterograph to __DGL__ using __Networkx__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5C-NW4amZ815"
   },
   "outputs": [],
   "source": [
    "vcols = {\"incident\": {\"D_sys_mod_count\", \"D_sys_mod_count\", \"D_reopen_count\", \"urgency\", \"incident_state\",\n",
    "                      \"u_symptom\", \"impact\", \"contact_type\", \"u_priority_confirmation\", \"cmdb_ci\",\n",
    "                      \"rfc\", \"problem_id\", \"caused_by\", \"location\", \"knowledge\", \"resolved_by\",\n",
    "                      \"subcategory\", \"active\", \"category\", \"priority\", \"reassigned\", \"node_id\"},\n",
    "         \"support_org\": {\"assigned_to\", \"assignment_group\", \"node_id\"},\n",
    "         \"customer\": {\"opened_by\", \"node_id\"},\n",
    "         \"vendor\": {\"vendor\", \"node_id\"}}\n",
    "ecols = {\"incident_support_org\": {\"_from\", \"_to\"}, \"incident_customer\": {\"_from\", \"_to\"},\n",
    "         \"incident_vendor\": {\"_from\", \"_to\"}}\n",
    "\n",
    "itsm_attributes = {'vertexCollections': vcols, 'edgeCollections': ecols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8KCUbNi_0Eu"
   },
   "source": [
    "After the graph structure has been defined, instantiate the _DGLArangoDB_Networkx_Adapter_ with connection and create the __dgl graph__ as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qACbcQBbLEx"
   },
   "outputs": [],
   "source": [
    "from adbnx_adapter.dgl_arangoDB_networkx_adapter import DGLArangoDB_Networkx_Adapter\n",
    "itsmg = DGLArangoDB_Networkx_Adapter(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yBIgn6fGbPo1"
   },
   "outputs": [],
   "source": [
    "g, labels = itsmg.create_networkx_graph(\n",
    "    graph_name='ITSMGraph',  graph_attributes=itsm_attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvY1SS3u_0E3"
   },
   "source": [
    "## Visually Inspect the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KL6fN4wbfW3"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "nx.draw_networkx(g.metagraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uMb3qm6_0E8"
   },
   "source": [
    "## Define the GCN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTqlOrYA_0E8"
   },
   "source": [
    "_Note_ :Node attributes have been discretized. An embedding layer is used to generate feature representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UyDWiVL8bSny"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "class HeteroRGCNLayer1(nn.Module):\n",
    "    EMBED_SIZE = 64\n",
    "    VOCAB_SIZE = 2386\n",
    "\n",
    "    def __init__(self, hidden_size, G):\n",
    "        super(HeteroRGCNLayer1, self).__init__()\n",
    "        # Need an embedding layer for each node feature\n",
    "        self.node_embeddings = {}\n",
    "        #self.dropouts = {}\n",
    "        for ntype in G.ntypes:\n",
    "            # create an embedding for each feature of a node\n",
    "            self.node_embeddings[ntype] = {}\n",
    "            num_node_features = G.node_attr_schemes(ntype)['f'].shape[0]\n",
    "            for feature in range(num_node_features):\n",
    "                self.node_embeddings[ntype][feature] = nn.Embedding(\n",
    "                    self.VOCAB_SIZE, self.EMBED_SIZE)\n",
    "            #self.dropouts[ntype] = nn.Dropout()\n",
    "        # for name in etypes:\n",
    "        module_layers = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
    "            module_layers[etype] = nn.Linear(\n",
    "                num_features * self.EMBED_SIZE, hidden_size)\n",
    "        self.weight = nn.ModuleDict(module_layers)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, G):\n",
    "\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # for each node compute the embedding and store it in the graph\n",
    "            # iterate over the features of each node and compute the embedding\n",
    "            the_node_embedding = self.node_embeddings[srctype]\n",
    "            node_feature_embeddings = []\n",
    "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
    "            for feature in range(num_features):\n",
    "                feature_embedding_layer = the_node_embedding[feature]\n",
    "                node_feature_embeddings.append(feature_embedding_layer(\n",
    "                    G.nodes[srctype].data['f'][:, feature]))\n",
    "            comp_node_embedding = torch.cat(node_feature_embeddings, 1)\n",
    "            G.nodes[srctype].data['E'] = comp_node_embedding\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](G.nodes[srctype].data['E'])\n",
    "            #Wh = torch.sum(Wh, dim = 1)\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return G\n",
    "        return {ntype: G.nodes[ntype].data['h'] for ntype in G.ntypes}\n",
    "\n",
    "\n",
    "class HeteroRGCNLayer2(nn.Module):\n",
    "    def __init__(self, in_size, out_size, etypes):\n",
    "        super(HeteroRGCNLayer2, self).__init__()\n",
    "        # W_r for each relation\n",
    "\n",
    "        self.weight = nn.ModuleDict({\n",
    "            name: nn.Linear(in_size, out_size) for name in etypes\n",
    "        })\n",
    "\n",
    "    def forward(self, G, feat_dict):\n",
    "        # The input is a dictionary of node features for each type\n",
    "        funcs = {}\n",
    "        for srctype, etype, dsttype in G.canonical_etypes:\n",
    "            # Compute W_r * h\n",
    "            Wh = self.weight[etype](feat_dict[srctype])\n",
    "            # Save it in graph for message passing\n",
    "            G.nodes[srctype].data['Wh2_%s' % etype] = Wh\n",
    "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
    "            # Note that the results are saved to the same destination feature 'h', which\n",
    "            # hints the type wise reducer for aggregation.\n",
    "            funcs[etype] = (fn.copy_u('Wh2_%s' %\n",
    "                                      etype, 'm'), fn.mean('m', 'h2'))\n",
    "        # Trigger message passing of multiple types.\n",
    "        # The first argument is the message passing functions for each relation.\n",
    "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
    "        # \"min\", \"mean\", \"stack\"\n",
    "        G.multi_update_all(funcs, 'sum')\n",
    "        # return G\n",
    "        # return the updated node feature dictionary\n",
    "        return {ntype: G.nodes[ntype].data['h2'] for ntype in G.ntypes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mjsfj08cboEx"
   },
   "outputs": [],
   "source": [
    "class HeteroRGCN(nn.Module):\n",
    "    def __init__(self, G, hidden_size, out_size):\n",
    "        super(HeteroRGCN, self).__init__()\n",
    "        # create layers\n",
    "        self.layer1 = HeteroRGCNLayer1(hidden_size, G)\n",
    "        self.layer2 = HeteroRGCNLayer2(hidden_size, out_size, G.etypes)\n",
    "\n",
    "    def forward(self, G):\n",
    "\n",
    "        h_dict = self.layer1(G)\n",
    "        h_dict = {k: F.leaky_relu(h) for k, h in h_dict.items()}\n",
    "        h_dict = self.layer2(G, h_dict)\n",
    "\n",
    "        # get paper logits\n",
    "\n",
    "        return h_dict['incident']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqMjZoSO_0FE"
   },
   "source": [
    "## Create Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z2YZAGfgbsSy"
   },
   "outputs": [],
   "source": [
    "training_mask = np.random.rand(len(labels)) <= 0.8\n",
    "train_idx = [i for i in range(len(labels)) if training_mask[i]]\n",
    "test_idx = [i for i in range(len(labels)) if not training_mask[i]]\n",
    "train_idx = torch.tensor(train_idx).long()\n",
    "test_idx = torch.tensor(test_idx).long()\n",
    "labels = torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJIloQV-_0FI"
   },
   "source": [
    "## Train and Evaluate the Model on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XH-d0z3ibzJ0"
   },
   "outputs": [],
   "source": [
    "%time\n",
    "# Create the model. The output has three logits for three classes.\n",
    "\n",
    "\n",
    "#model = HeteroRGCN(G, 512,64, 2)\n",
    "\n",
    "#opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "# ,\n",
    "model = HeteroRGCN(g, 32, 2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    opt.zero_grad()\n",
    "    logits = model(g)\n",
    "    # The loss is computed only for labeled nodes.\n",
    "    loss = loss_fn(logits[train_idx], labels[train_idx])\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    pred_trng = torch.argmax(logits[train_idx], dim=1)\n",
    "    res_trng = pred_trng == labels[train_idx]\n",
    "    trng_acc = torch.sum(res_trng).item()/labels[train_idx].shape[0]\n",
    "\n",
    "    pred_test = torch.argmax(logits[test_idx], dim=1)\n",
    "    res_test = pred_test == labels[test_idx]\n",
    "    test_acc = torch.sum(res_test).item()/labels[test_idx].shape[0]\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print('Loss %.4f, training accuracy %.4f, test accuracy %.4f' %\n",
    "              (loss.item(), trng_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_B6fTCvt_0FM"
   },
   "source": [
    "## Note\n",
    "The implementation comes with a database dump required for this exercise. If there is a need to recreate the dump, remove the existing creds.dat file and create an empty creds.dat file. The $\\texttt{itsm_data_load_driver}$ can then be used to load the data to an __Oasis__ instance. The data load procedure can take about $15$ minutes to complete. Once, the data load is done, the _arangodump_ utility can be used to create a dump of the loaded data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZucEAm4_0FM"
   },
   "outputs": [],
   "source": [
    "!rm creds.dat\n",
    "!touch creds.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsJyZCgz_0FQ"
   },
   "outputs": [],
   "source": [
    "from itsm_data_load_driver import load_ITSM_data_to_ArangoDB\n",
    "itsmdl = load_ITSM_data_to_ArangoDB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bto7Q0qa_0FT"
   },
   "outputs": [],
   "source": [
    "#arangodump --server.endpoint <put server address eg., http+ssl://5904e8d8a65f.arangodb.cloud:8529> --server.username <put user name>  --server.database <put dbName> --server.password <put passwd> --output-directory dgl_data_dump\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "ITSM_ArangoDB_Adapter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

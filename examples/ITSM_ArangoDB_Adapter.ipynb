{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ITSM_ArangoDB_Adapter.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOHObJgsmTRQT4nlfFh0158",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arangoml/networkx-adapter/blob/dgl_updates/examples/ITSM_ArangoDB_Adapter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF_RsnbzZsAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!git clone -b dgl_updates https://github.com/arangoml/networkx-adapter.git\n",
        "!rsync -av networkx-adapter/examples/ ./ --exclude=.git\n",
        "!pip3 install networkx\n",
        "!pip3 install matplotlib\n",
        "!pip3 install --index-url https://test.pypi.org/simple/ adbnx-adapter==0.0.0.2.5\n",
        "!pip3 install pyarango\n",
        "!pip3 install python-arango\n",
        "!pip install dgl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhIdp2rNaos7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import oasis\n",
        "con = oasis.getTempCredentials()\n",
        "\n",
        "print()\n",
        "print(\"https://{}:{}\".format(con[\"hostname\"], con[\"port\"]))\n",
        "print(\"Username: \" + con[\"username\"])\n",
        "print(\"Password: \" + con[\"password\"])\n",
        "print(\"Database: \" + con[\"dbName\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Q1aESiatNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!./tools/arangorestore -c none --server.endpoint http+ssl://{con[\"hostname\"]}:{con[\"port\"]} --server.username {con[\"username\"]} --server.database {con[\"dbName\"]} --server.password {con[\"password\"]} --default-replication-factor 3  --input-directory \"data/dgl_data_dump\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C-NW4amZ815",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "vcols = {\"incident\":{\"D_sys_mod_count\", \"D_sys_mod_count\", \"D_reopen_count\", \"urgency\", \"incident_state\",\\\n",
        "                     \"u_symptom\", \"impact\", \"contact_type\",\"u_priority_confirmation\", \"cmdb_ci\",\\\n",
        "                      \"rfc\", \"problem_id\", \"caused_by\", \"location\", \"knowledge\", \"resolved_by\",\\\n",
        "                     \"subcategory\", \"active\", \"category\", \"priority\", \"reassigned\", \"node_id\"},\\\n",
        "         \"support_org\": { \"assigned_to\", \"assignment_group\", \"node_id\"},\\\n",
        "         \"customer\": {\"opened_by\", \"node_id\"},\\\n",
        "        \"vendor\": {\"vendor\", \"node_id\"}}\n",
        "ecols = {\"incident_support_org\": {\"_from\", \"_to\"}, \"incident_customer\": {\"_from\", \"_to\"},\\\n",
        "         \"incident_vendor\": {\"_from\", \"_to\"}}\n",
        "         \n",
        "itsm_attributes = {'vertexCollections': vcols, 'edgeCollections': ecols}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qACbcQBbLEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from adbnx_adapter.dgl_arangoDB_networkx_adapter import DGLArangoDB_Networkx_Adapter\n",
        "itsmg = DGLArangoDB_Networkx_Adapter(con)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBIgn6fGbPo1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g, labels = itsmg.create_networkx_graph(graph_name = 'ITSMGraph',  graph_attributes =   itsm_attributes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KL6fN4wbfW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "nx.draw_networkx(g.metagraph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyDWiVL8bSny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "\n",
        "class HeteroRGCNLayer1(nn.Module):\n",
        "    EMBED_SIZE = 64\n",
        "    VOCAB_SIZE = 2386\n",
        "    def __init__(self, hidden_size, G):\n",
        "        super(HeteroRGCNLayer1, self).__init__()\n",
        "        # Need an embedding layer for each node feature\n",
        "        self.node_embeddings = {}\n",
        "        #self.dropouts = {}\n",
        "        for ntype in G.ntypes:\n",
        "            # create an embedding for each feature of a node\n",
        "            self.node_embeddings[ntype] = {}\n",
        "            num_node_features = G.node_attr_schemes(ntype)['f'].shape[0]\n",
        "            for feature in range(num_node_features):\n",
        "                self.node_embeddings[ntype][feature] = nn.Embedding(self.VOCAB_SIZE, self.EMBED_SIZE)\n",
        "            #self.dropouts[ntype] = nn.Dropout()\n",
        "        #for name in etypes:\n",
        "        module_layers = {}\n",
        "        for srctype, etype, dsttype in G.canonical_etypes:\n",
        "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
        "            module_layers[etype] = nn.Linear(num_features * self.EMBED_SIZE, hidden_size)\n",
        "        self.weight = nn.ModuleDict(module_layers)\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, G):\n",
        "\n",
        "        funcs = {}\n",
        "        for srctype, etype, dsttype in G.canonical_etypes:\n",
        "            # for each node compute the embedding and store it in the graph\n",
        "            # iterate over the features of each node and compute the embedding\n",
        "            the_node_embedding = self.node_embeddings[srctype]\n",
        "            node_feature_embeddings = []\n",
        "            num_features = G.node_attr_schemes(srctype)['f'].shape[0]\n",
        "            for feature in range(num_features):\n",
        "                feature_embedding_layer = the_node_embedding[feature]\n",
        "                node_feature_embeddings.append(feature_embedding_layer(G.nodes[srctype].data['f'][:, feature]))\n",
        "            comp_node_embedding = torch.cat(node_feature_embeddings, 1)\n",
        "            G.nodes[srctype].data['E'] = comp_node_embedding\n",
        "            # Compute W_r * h\n",
        "            Wh = self.weight[etype](G.nodes[srctype].data['E'])  \n",
        "            #Wh = torch.sum(Wh, dim = 1)\n",
        "                # Save it in graph for message passing\n",
        "            G.nodes[srctype].data['Wh_%s' % etype] = Wh\n",
        "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
        "            # Note that the results are saved to the same destination feature 'h', which\n",
        "            # hints the type wise reducer for aggregation.\n",
        "            funcs[etype] = (fn.copy_u('Wh_%s' % etype, 'm'), fn.mean('m', 'h'))\n",
        "        # Trigger message passing of multiple types.\n",
        "        # The first argument is the message passing functions for each relation.\n",
        "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
        "        # \"min\", \"mean\", \"stack\"\n",
        "        G.multi_update_all(funcs, 'sum')\n",
        "        #return G\n",
        "        return {ntype : G.nodes[ntype].data['h'] for ntype in G.ntypes}\n",
        "\n",
        "class HeteroRGCNLayer2(nn.Module):\n",
        "    def __init__(self, in_size, out_size, etypes):\n",
        "        super(HeteroRGCNLayer2, self).__init__()\n",
        "        # W_r for each relation\n",
        "        \n",
        "        self.weight = nn.ModuleDict({\n",
        "                name : nn.Linear(in_size, out_size) for name in etypes\n",
        "            })\n",
        "\n",
        "    def forward(self, G, feat_dict):\n",
        "        # The input is a dictionary of node features for each type\n",
        "        funcs = {}\n",
        "        for srctype, etype, dsttype in G.canonical_etypes:\n",
        "            # Compute W_r * h\n",
        "            Wh = self.weight[etype](feat_dict[srctype])\n",
        "            # Save it in graph for message passing\n",
        "            G.nodes[srctype].data['Wh2_%s' % etype] = Wh\n",
        "            # Specify per-relation message passing functions: (message_func, reduce_func).\n",
        "            # Note that the results are saved to the same destination feature 'h', which\n",
        "            # hints the type wise reducer for aggregation.\n",
        "            funcs[etype] = (fn.copy_u('Wh2_%s' % etype, 'm'), fn.mean('m', 'h2'))\n",
        "        # Trigger message passing of multiple types.\n",
        "        # The first argument is the message passing functions for each relation.\n",
        "        # The second one is the type wise reducer, could be \"sum\", \"max\",\n",
        "        # \"min\", \"mean\", \"stack\"\n",
        "        G.multi_update_all(funcs, 'sum')\n",
        "        #return G\n",
        "        # return the updated node feature dictionary\n",
        "        return {ntype : G.nodes[ntype].data['h2'] for ntype in G.ntypes}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mjsfj08cboEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeteroRGCN(nn.Module):\n",
        "    def __init__(self, G, hidden_size, out_size):\n",
        "        super(HeteroRGCN, self).__init__()\n",
        "        # create layers\n",
        "        self.layer1 = HeteroRGCNLayer1(hidden_size, G)\n",
        "        self.layer2 = HeteroRGCNLayer2(hidden_size, out_size, G.etypes)\n",
        "\n",
        "        \n",
        "\n",
        "    def forward(self, G):\n",
        "        \n",
        "        h_dict = self.layer1(G)\n",
        "        h_dict = {k : F.leaky_relu(h) for k, h in h_dict.items()}\n",
        "        h_dict = self.layer2(G, h_dict)\n",
        "        \n",
        "        # get paper logits\n",
        "        \n",
        "        return h_dict['incident']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2YZAGfgbsSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_mask = np.random.rand(len(labels)) <= 0.8\n",
        "train_idx = [i for i in range(len(labels)) if training_mask[i]]\n",
        "test_idx = [i for i in range(len(labels)) if not training_mask[i]]\n",
        "train_idx = torch.tensor(train_idx).long()\n",
        "test_idx = torch.tensor(test_idx).long()\n",
        "labels = torch.tensor(labels).long()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH-d0z3ibzJ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "# Create the model. The output has three logits for three classes.\n",
        "\n",
        "\n",
        "#model = HeteroRGCN(G, 512,64, 2)\n",
        "\n",
        "#opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "#,\n",
        "model = HeteroRGCN(g,32,2)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(100):\n",
        "    opt.zero_grad()\n",
        "    logits = model(g)\n",
        "    # The loss is computed only for labeled nodes.\n",
        "    loss = loss_fn(logits[train_idx], labels[train_idx])\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    pred_trng = torch.argmax(logits[train_idx], dim = 1)\n",
        "    res_trng = pred_trng == labels[train_idx]\n",
        "    trng_acc = torch.sum(res_trng).item()/labels[train_idx].shape[0]\n",
        "    \n",
        "    pred_test = torch.argmax(logits[test_idx], dim = 1)\n",
        "    res_test = pred_test == labels[test_idx]\n",
        "    test_acc = torch.sum(res_test).item()/labels[test_idx].shape[0]\n",
        "    \n",
        "    \n",
        "   \n",
        "    if epoch % 10 == 0:\n",
        "        print( 'Loss %.4f, training accuracy %.4f, test accuracy %.4f' % ( loss.item(), trng_acc, test_acc ) )"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}